{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d778b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tayyi\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time Global_active_power Global_reactive_power  Voltage  \\\n",
       "0  16/12/2006  17:24:00               4.216                 0.418  234.840   \n",
       "1  16/12/2006  17:25:00               5.360                 0.436  233.630   \n",
       "2  16/12/2006  17:26:00               5.374                 0.498  233.290   \n",
       "3  16/12/2006  17:27:00               5.388                 0.502  233.740   \n",
       "4  16/12/2006  17:28:00               3.666                 0.528  235.680   \n",
       "\n",
       "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
       "0           18.400          0.000          1.000            17.0  \n",
       "1           23.000          0.000          1.000            16.0  \n",
       "2           23.000          0.000          2.000            17.0  \n",
       "3           23.000          0.000          1.000            17.0  \n",
       "4           15.800          0.000          1.000            17.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import packages\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import os\n",
    "\n",
    "# read the dataset into python\n",
    "df = pd.read_csv('C:/Users/tayyi/Downloads/archive/household_power_consumption.txt', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32b9577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns after removing missing values: (2049280, 2)\n",
      "The time series starts from:  2006-12-16 17:24:00\n",
      "The time series ends on:  2010-12-11 23:59:00\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['date_time'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "df['Global_active_power'] = pd.to_numeric(df['Global_active_power'], errors='coerce')\n",
    "df = df.dropna(subset=['Global_active_power'])\n",
    "\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "\n",
    "df = df.loc[:, ['date_time', 'Global_active_power']]\n",
    "df.sort_values('date_time', inplace=True, ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print('Number of rows and columns after removing missing values:', df.shape)\n",
    "print('The time series starts from: ', df['date_time'].min())\n",
    "print('The time series ends on: ', df['date_time'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85f169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2049280 entries, 0 to 2049279\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   date_time            datetime64[ns]\n",
      " 1   Global_active_power  float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 31.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>Global_active_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16 17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-16 17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-16 17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-16 17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-16 17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006-12-16 17:29:00</td>\n",
       "      <td>3.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006-12-16 17:30:00</td>\n",
       "      <td>3.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006-12-16 17:31:00</td>\n",
       "      <td>3.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006-12-16 17:32:00</td>\n",
       "      <td>3.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006-12-16 17:33:00</td>\n",
       "      <td>3.662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  Global_active_power\n",
       "0 2006-12-16 17:24:00                4.216\n",
       "1 2006-12-16 17:25:00                5.360\n",
       "2 2006-12-16 17:26:00                5.374\n",
       "3 2006-12-16 17:27:00                5.388\n",
       "4 2006-12-16 17:28:00                3.666\n",
       "5 2006-12-16 17:29:00                3.520\n",
       "6 2006-12-16 17:30:00                3.702\n",
       "7 2006-12-16 17:31:00                3.700\n",
       "8 2006-12-16 17:32:00                3.668\n",
       "9 2006-12-16 17:33:00                3.662"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2188807",
   "metadata": {},
   "source": [
    "test_cutoff_date = df['date_time'].max() - timedelta(days=7)\n",
    "val_cutoff_date = test_cutoff_date - timedelta(days=14)\n",
    "\n",
    "df_test = df[df['date_time'] > test_cutoff_date]\n",
    "df_val = df[(df['date_time'] > val_cutoff_date) & (df['date_time'] <= test_cutoff_date)]\n",
    "df_train = df[df['date_time'] <= val_cutoff_date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5343fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ts_files(dataset, \n",
    "                    start_index, \n",
    "                    end_index, \n",
    "                    history_length, \n",
    "                    step_size, \n",
    "                    target_step, \n",
    "                    num_rows_per_file, \n",
    "                    data_folder):\n",
    "    assert step_size > 0\n",
    "    assert start_index >= 0\n",
    "    \n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    \n",
    "    time_lags = sorted(range(target_step+1, target_step+history_length+1, step_size), reverse=True)\n",
    "    col_names = [f'x_lag{i}' for i in time_lags] + ['y']\n",
    "    start_index = start_index + history_length\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_step\n",
    "    \n",
    "    rng = range(start_index, end_index)\n",
    "    num_rows = len(rng)\n",
    "    num_files = math.ceil(num_rows/num_rows_per_file)\n",
    "    \n",
    "    print(f'Creating {num_files} files.')\n",
    "    for i in range(num_files):\n",
    "        filename = f'{data_folder}/ts_file{i}.pkl'\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f'{filename}')\n",
    "            \n",
    "        ind0 = i*num_rows_per_file\n",
    "        ind1 = min(ind0 + num_rows_per_file, end_index)\n",
    "        data_list = []\n",
    "        \n",
    "        for j in range(ind0, ind1):\n",
    "            indices = range(j-1, j-history_length-1, -step_size)\n",
    "            data = dataset[sorted(indices) + [j+target_step]]\n",
    "            \n",
    "            data_list.append(data)\n",
    "\n",
    "        df_ts = pd.DataFrame(data=data_list, columns=col_names)\n",
    "        df_ts.to_pickle(filename)\n",
    "            \n",
    "    return len(col_names)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba749566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 158 files.\n",
      "ts_data/ts_file0.pkl\n",
      "ts_data/ts_file10.pkl\n",
      "ts_data/ts_file20.pkl\n",
      "ts_data/ts_file30.pkl\n",
      "ts_data/ts_file40.pkl\n",
      "ts_data/ts_file50.pkl\n",
      "ts_data/ts_file60.pkl\n",
      "ts_data/ts_file70.pkl\n",
      "ts_data/ts_file80.pkl\n",
      "ts_data/ts_file90.pkl\n",
      "ts_data/ts_file100.pkl\n",
      "ts_data/ts_file110.pkl\n",
      "ts_data/ts_file120.pkl\n",
      "ts_data/ts_file130.pkl\n",
      "ts_data/ts_file140.pkl\n",
      "ts_data/ts_file150.pkl\n",
      "Wall time: 23min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "global_active_power = df_train['Global_active_power'].values\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "global_active_power_scaled = scaler.fit_transform(global_active_power.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_length = 7*24*60  \n",
    "step_size = 10 \n",
    "target_step = 10 \n",
    "                  \n",
    "\n",
    "num_timesteps = create_ts_files(global_active_power_scaled,\n",
    "                                start_index=0,\n",
    "                                end_index=None,\n",
    "                                history_length=history_length,\n",
    "                                step_size=step_size,\n",
    "                                target_step=target_step,\n",
    "                                num_rows_per_file=128*100,\n",
    "                                data_folder='ts_data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d317369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesLoader:\n",
    "    def __init__(self, ts_folder, filename_format):\n",
    "        self.ts_folder = ts_folder\n",
    "        \n",
    "        i = 0\n",
    "        file_found = True\n",
    "        while file_found:\n",
    "            filename = self.ts_folder + '/' + filename_format.format(i)\n",
    "            file_found = os.path.exists(filename)\n",
    "            if file_found:\n",
    "                i += 1\n",
    "                \n",
    "        self.num_files = i\n",
    "        self.files_indices = np.arange(self.num_files)\n",
    "        self.shuffle_chunks()\n",
    "        \n",
    "    def num_chunks(self):\n",
    "        return self.num_files\n",
    "    \n",
    "    def get_chunk(self, idx):\n",
    "        assert (idx >= 0) and (idx < self.num_files)\n",
    "        \n",
    "        ind = self.files_indices[idx]\n",
    "        filename = self.ts_folder + '/' + filename_format.format(ind)\n",
    "        df_ts = pd.read_pickle(filename)\n",
    "        num_records = len(df_ts.index)\n",
    "        \n",
    "        features = df_ts.drop('y', axis=1).values\n",
    "        target = df_ts['y'].values\n",
    "        \n",
    "        features_batchmajor = np.array(features).reshape(num_records, -1, 1)\n",
    "        return features_batchmajor, target\n",
    "    \n",
    "    def shuffle_chunks(self):\n",
    "        np.random.shuffle(self.files_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f545e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_folder = 'ts_data'\n",
    "filename_format = 'ts_file{}.pkl'\n",
    "tss = TimeSeriesLoader(ts_folder, filename_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9affb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_inputs = tf.keras.Input(shape=(num_timesteps, 1))\n",
    "\n",
    "x = layers.LSTM(units=10)(ts_inputs)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "model = tf.keras.Model(inputs=ts_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7d418a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240a0621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1008, 1)]         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10)                480       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07387872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0\n",
      "100/100 [==============================] - 33s 300ms/step - loss: 0.0109 - mse: 0.0109\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0109 - mse: 0.0109\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0135 - mse: 0.0135\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0089 - mse: 0.0089\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0072 - mse: 0.0072\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0081 - mse: 0.0081\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0122 - mse: 0.0122\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0091 - mse: 0.0091\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.0067 - mse: 0.0067\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0062 - mse: 0.0062\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 0.0097 - mse: 0.0097\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.0070 - mse: 0.0070\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 0.0068 - mse: 0.0068\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 0.0064 - mse: 0.0064\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.0091 - mse: 0.0091\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.0079 - mse: 0.0079\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0058 - mse: 0.0058\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.0075 - mse: 0.0075\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0087 - mse: 0.0087\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0070 - mse: 0.0070\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.0084 - mse: 0.0084\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0061 - mse: 0.0061\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 0.0067 - mse: 0.0067\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 0.0069 - mse: 0.0069\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0091 - mse: 0.0091\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0066 - mse: 0.0066\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0024 - mse: 0.0024\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0025 - mse: 0.0025\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0020 - mse: 0.0020\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0032 - mse: 0.0032\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0063 - mse: 0.0063\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0024 - mse: 0.0024\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0069 - mse: 0.0069\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0027 - mse: 0.0027\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0080 - mse: 0.0080\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0053 - mse: 0.0053\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0062 - mse: 0.0062\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0036 - mse: 0.0036\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0069 - mse: 0.0069\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0025 - mse: 0.0025\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 0.0067 - mse: 0.0067\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0016 - mse: 0.0016\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0059 - mse: 0.0059\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.0052 - mse: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0061 - mse: 0.0061\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0045 - mse: 0.0045\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0041 - mse: 0.0041\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0057 - mse: 0.0057\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0050 - mse: 0.0050\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0037 - mse: 0.0037\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0049 - mse: 0.0049\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0052 - mse: 0.0052\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0076 - mse: 0.0076\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0057 - mse: 0.0057\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0079 - mse: 0.0079\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0043 - mse: 0.0043\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0066 - mse: 0.0066\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0068 - mse: 0.0068\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 8.1498e-04 - mse: 8.1498e-04\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0061 - mse: 0.0061\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0040 - mse: 0.0040\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0065 - mse: 0.0065\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0060 - mse: 0.0060\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0062 - mse: 0.0062\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0089 - mse: 0.0089\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0054 - mse: 0.0054\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0065 - mse: 0.0065\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0035 - mse: 0.0035\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 0.0044 - mse: 0.0044\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0034 - mse: 0.0034\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 0.0073 - mse: 0.0073\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0039 - mse: 0.0039\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 0.0046 - mse: 0.0046\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0042 - mse: 0.0042\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0017 - mse: 0.0017\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0051 - mse: 0.0051\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0057 - mse: 0.0057\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 0.0055 - mse: 0.0055\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 0.0067 - mse: 0.0067\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 0.0047 - mse: 0.0047\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 0.0048 - mse: 0.0048\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Wall time: 1h 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train in batch sizes of 128.\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 1\n",
    "NUM_CHUNKS = tss.num_chunks()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('epoch #{}'.format(epoch))\n",
    "    for i in range(NUM_CHUNKS):\n",
    "        X, y = tss.get_chunk(i)\n",
    "        \n",
    "        # model.fit does train the model incrementally. ie. Can call multiple times in batches.\n",
    "        # https://github.com/keras-team/keras/issues/4446\n",
    "        model.fit(x=X, y=y, batch_size=BATCH_SIZE)\n",
    "        \n",
    "    # shuffle the chunks so they're not in the same order next time around.\n",
    "    tss.shuffle_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d5071af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1 files.\n",
      "ts_val_data/ts_file0.pkl\n"
     ]
    }
   ],
   "source": [
    "global_active_power_val = df_val['Global_active_power'].values\n",
    "global_active_power_val_scaled = scaler.transform(global_active_power_val.reshape(-1, 1)).reshape(-1, )\n",
    "\n",
    "history_length = 7*24*60 \n",
    "step_size = 10             \n",
    "target_step = 10 \n",
    "\n",
    "num_timesteps = create_ts_files(global_active_power_val_scaled,\n",
    "                                start_index=0,\n",
    "                                end_index=None,\n",
    "                                history_length=history_length,\n",
    "                                step_size=step_size,\n",
    "                                target_step=target_step,\n",
    "                                num_rows_per_file=128*100,\n",
    "                                data_folder='ts_val_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac2e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation mean squared error: 0.43897046945288226\n",
      "validation baseline mean squared error: 0.428345914375\n"
     ]
    }
   ],
   "source": [
    "df_val_ts = pd.read_pickle('ts_val_data/ts_file0.pkl')\n",
    "\n",
    "\n",
    "features = df_val_ts.drop('y', axis=1).values\n",
    "features_arr = np.array(features)\n",
    "\n",
    "num_records = len(df_val_ts.index)\n",
    "features_batchmajor = features_arr.reshape(num_records, -1, 1)\n",
    "\n",
    "\n",
    "y_pred = model.predict(features_batchmajor).reshape(-1, )\n",
    "y_pred = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1 ,)\n",
    "\n",
    "y_act = df_val_ts['y'].values\n",
    "y_act = scaler.inverse_transform(y_act.reshape(-1, 1)).reshape(-1 ,)\n",
    "\n",
    "print('Error: {}'.format(mean_squared_error(y_act, y_pred)))\n",
    "\n",
    "y_pred_baseline = df_val_ts['x_lag11'].values\n",
    "y_pred_baseline = scaler.inverse_transform(y_pred_baseline.reshape(-1, 1)).reshape(-1 ,)\n",
    "print('Error: {}'.format(mean_squared_error(y_act, y_pred_baseline)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2386c2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
